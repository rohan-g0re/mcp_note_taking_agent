# ğŸ¤– MCP Notetaking Agent

A simplified AI agent powered by Google Gemini 2.0 Flash and LangChain's ReAct framework for intelligent question-answering with automatic conversation history saving.

## Current Implementation

**Simple & Clean**: Ask questions, get AI responses, save complete conversation history on exit.

```mermaid
graph TD
    A["ğŸš€ Start Application<br/>python agent_langchain.py"] --> B["âš™ï¸ Initialize Agent<br/>Silent Setup"]
    
    B --> C["ğŸ§  Setup Components"]
    C --> C1["ğŸ¤– Gemini LLM<br/>gemini-2.0-flash"]
    C --> C2["ğŸ” Google Embeddings<br/>models/embedding-001"]
    C --> C3["ğŸ“Š FAISS Vector Store<br/>For conversation search"]
    C --> C4["ğŸ› ï¸ Create Tools<br/>Ask Question + Final Answer"]
    C --> C5["ğŸ­ ReAct Agent<br/>hwchase17/react template"]
    C --> C6["âš¡ Agent Executor<br/>Orchestration layer"]
    
    C6 --> D["âœ… Agent Ready<br/>ğŸ¤– MCP Agent Ready<br/>Type 'quit' to exit and save"]
    
    D --> E["ğŸ’¬ User Input<br/>You: [question]"]
    
    E --> F{"ğŸ” Input Type?"}
    
    F -->|"quit"| G["ğŸ’¾ Save Complete History"]
    F -->|"question"| H["ğŸ¤– Process with ReAct Agent"]
    
    H --> H1["ğŸ§  Agent Reasoning<br/>Analyze question"]
    H1 --> H2["ğŸ› ï¸ Tool Selection<br/>Ask Question tool"]
    H2 --> H3["ğŸŒ Gemini API Call<br/>Get AI response"]
    H3 --> H4["ğŸ“ Store in History<br/>Q&A pair with timestamp"]
    H4 --> H5["ğŸ“Š Update Vector Store<br/>FAISS embeddings"]
    H5 --> H6["ğŸ¯ Final Answer Tool<br/>Format response"]
    
    H6 --> I["ğŸ“¤ Display Response<br/>Agent: [response]"]
    
    I --> J["ğŸ”„ Continue Loop"]
    J --> E
    
    G --> G1["ğŸ“ Create Markdown File<br/>conversation_history_TIMESTAMP.md"]
    G1 --> G2["ğŸ’¾ Write All Q&A Pairs<br/>Formatted with timestamps"]
    G2 --> G3["âœ… Confirm Save<br/>Display filename"]
    G3 --> K["ğŸ Exit Application"]
    
    style A fill:#e1f5fe
    style D fill:#f3e5f5
    style H1 fill:#fff3e0
    style G1 fill:#e8f5e8
    style K fill:#ffebee
```

## Architecture Overview

### **Core Components:**
- **ğŸ§  LLM**: Google Gemini 2.0 Flash (free tier)
- **ğŸ” Embeddings**: Google's embedding-001 model
- **ğŸ“Š Vector Store**: FAISS for semantic conversation search
- **ğŸ­ Agent Framework**: LangChain ReAct (Reasoning + Acting)
- **ğŸ’¾ Memory**: Persistent conversation history with auto-save

### **Tools Available:**
1. **Ask Question**: Direct interaction with Gemini AI
2. **Final Answer**: Prevents infinite reasoning loops

### **Key Features:**
- âœ… **Clean Interface**: Minimal terminal output
- âœ… **Smart Responses**: ReAct reasoning for better answers  
- âœ… **Memory Management**: Automatic conversation storage
- âœ… **Error Handling**: Graceful fallbacks for API limits
- âœ… **Vector Search**: Semantic search through conversation history

## Quick Start

### 1. Setup Environment
```bash
# Clone and navigate to project
git clone <repository-url>
cd 101_mcp_agent_v1

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows
venv\Scripts\activate
# Mac/Linux  
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Configure API Key
Create a `.env` file in the project root:
```env
GOOGLE_API_KEY=your_gemini_api_key_here
```

**Get your FREE Gemini API key**: https://makersuite.google.com/app/apikey

### 3. Run the Agent
```bash
python agent_langchain.py
```

## Usage Example

```
ğŸ¤– MCP Agent Ready
Type 'quit' to exit and save conversation history

You: What is machine learning?
Agent: Machine learning is a branch of artificial intelligence that enables computers to learn and make decisions from data without being explicitly programmed...

You: Explain neural networks
Agent: Neural networks are computing systems inspired by biological neural networks...

You: quit
Conversation saved to conversation_history_20250605_143052.md
```

## Output Files

When you type `quit`, the agent automatically saves your complete conversation history to a timestamped markdown file:

**Example: `conversation_history_20250605_143052.md`**
```markdown
# ğŸ“ Complete Conversation History
**Date**: 2025-06-05 14:30:52
**Total Conversations**: 2

---

## Conversation 1
**Time**: 2025-06-05 14:28:15

**Q**: What is machine learning?

**A**: Machine learning is a branch of artificial intelligence...

---

## Conversation 2
**Time**: 2025-06-05 14:29:45

**Q**: Explain neural networks

**A**: Neural networks are computing systems...

---
```

## Features

- âœ… **Zero Configuration**: Works out of the box with minimal setup
- âœ… **Free Tier**: Uses Google Gemini's generous free API
- âœ… **Smart AI**: ReAct framework for intelligent reasoning
- âœ… **Auto-Save**: Complete conversation history saved on exit
- âœ… **Clean Interface**: Minimal, distraction-free terminal UI
- âœ… **Error Resilient**: Graceful handling of API limits and errors